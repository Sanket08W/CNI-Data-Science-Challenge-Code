{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "a838562e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from math import cos, asin, sqrt, pi\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import sklearn.neighbors as neighbors\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd5317c",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "783e0191",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bmtc = pd.read_parquet('./BMTC.parquet.gzip')\n",
    "ip = pd.read_csv('./Input.csv',index_col=0)\n",
    "gt = pd.read_csv('./GroundTruth.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "8723812e",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data = pd.read_csv('./extract.csv')\n",
    "extracted_data_train = extracted_data[['Source_Lat','Source_Long','Dest_Lat','Dest_Long']]\n",
    "extracted_data_label = extracted_data['TT'].values\n",
    "# extracted_data = extracted_data.drop([])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9815b3",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "0b23b914",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_model(ip):\n",
    "    coords = np.vstack((ip[['Source_Lat',  'Source_Long']].values,\n",
    "                        ip[['Dest_Lat', 'Dest_Long']].values,\n",
    "                        ip[['Source_Lat',  'Source_Long']].values,\n",
    "                        ip[['Dest_Lat', 'Dest_Long']].values))\n",
    "    nc = 300\n",
    "    kmeans = MiniBatchKMeans(n_clusters=nc, batch_size=100).fit(coords)\n",
    "    return kmeans\n",
    "\n",
    "def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "    p = pi/180\n",
    "    a = 0.5 - cos((lat2-lat1)*p)/2 + cos(lat1*p) * cos(lat2*p) * (1-cos((lon2-lon1)*p))/2\n",
    "    return 12742 * asin(sqrt(a)) #2*R*asin...\n",
    "# lat1 = -34.83333#51.5007\n",
    "# lon1 = -58.5166646#0.1246\n",
    "# lat2 = 49.0083899664#40.6892\n",
    "# lon2 = 2.53844117956#74.0445\n",
    "# haversine_distance(lat1,lon1,lat2,lon2)\n",
    "def preprocess(df):\n",
    "    ip = copy.deepcopy(df)\n",
    "    ip['haversine_distance'] = ip.apply(lambda x: haversine_distance(x['Source_Lat'],  x['Source_Long'],x['Dest_Lat'], x['Dest_Long']), axis=1)\n",
    "    for i in range(nc):\n",
    "        ip[f'pickup_cluster_{i+1}'] = np.zeros(len(ip))\n",
    "        ip[f'dropoff_cluster{i+1}'] = np.zeros(len(ip))\n",
    "    for index in ip.index:\n",
    "        x  = ip.iloc[index]\n",
    "        p1 = kmeans.predict([[x['Source_Lat'],  x['Source_Long']]])\n",
    "        x[f'pickup_cluster_{p1}'] = 1\n",
    "        p2 = kmeans.predict([[x['Dest_Lat'], x['Dest_Long']]])\n",
    "        x[f'dropoff_cluster_{p2}'] = 1\n",
    "#     ip['dropoff_cluster'] = ip.apply(lambda x: kmeans.predict([[x['Dest_Lat'], x['Dest_Long']]])[0], axis=1)\n",
    "#     ip = pd.get_dummies(ip, columns = ['pickup_cluster','dropoff_cluster'])\n",
    "    return ip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f7e0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "given = preprocess(ip)\n",
    "# # x_train, x_test, y_train, y_test = train_test_split(o.values,gt.values,train_size=0.8,test_size=0.2)\n",
    "o = preprocess(extracted_data_train)\n",
    "# x_train, x_test, y_train, y_test = train_test_split(extracted_data_train,extracted_data_label,train_size=0.8,test_size=0.2)\n",
    "# frames = [given,o]\n",
    "# combine = pd.concat(frames)\n",
    "x_train, x_test, y_train, y_test = train_test_split(o,extracted_data_label,train_size=0.7,test_size=0.3,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "91f4b0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def score(y,y_pred):\n",
    "    # Score\n",
    "    mse = metrics.mean_squared_error(y, y_pred)\n",
    "    mae = metrics.mean_absolute_error(y, y_pred)\n",
    "    r2 = metrics.r2_score(y, y_pred)\n",
    "    print(f'mae: {np.round(mae, 4)}') # mse:{np.round(mse, 4)}    r2: {np.round(r2, 4)}     \n",
    "    return mae\n",
    "\n",
    "def model_output(X_train, X_test, y_train, y_test):\n",
    "    #Model Linear Regression\n",
    "    reg = linear_model.LinearRegression()\n",
    "    reg.fit(X_train, y_train)\n",
    "\n",
    "    # Predict\n",
    "    y_pred = reg.predict(X_train)\n",
    "    print(\"1) Linear Regression \")\n",
    "    print(\"Training Error:\")\n",
    "    score(y_train,y_pred)\n",
    "    y_pred = reg.predict(X_test)\n",
    "    print(\"Testing Error:\")\n",
    "    score(y_test,y_pred)\n",
    "    \n",
    "#     print(\"2) SVR\")\n",
    "#     regr = make_pipeline(StandardScaler(), SVR(C=1000, epsilon=0.01))\n",
    "#     regr.fit(X_train, y_train)\n",
    "#     # y_pred = regr.predict(one_hot_encoded_data)\n",
    "\n",
    "#     # Predict\n",
    "#     y_pred = regr.predict(X_train)\n",
    "#     print(\"Training Error:\")\n",
    "#     score(y_train,y_pred)\n",
    "#     y_pred = regr.predict(X_test)\n",
    "#     print(\"Testing Error:\")\n",
    "#     score(y_test,y_pred)\n",
    "    \n",
    "    print(\"3) DT\")\n",
    "    clf = tree.DecisionTreeRegressor()\n",
    "    clf = clf.fit(X_train, y_train)\n",
    "\n",
    "    # Predict\n",
    "    y_pred = clf.predict(X_train)\n",
    "    print(\"Training Error:\")\n",
    "    score(y_train,y_pred)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(\"Testing Error:\")\n",
    "    score(y_test,y_pred)\n",
    "    \n",
    "    print(\"4) Ensemble model\")\n",
    "    # Training classifiers\n",
    "    reg1 = GradientBoostingRegressor(random_state=1)\n",
    "    reg2 = neighbors.KNeighborsRegressor(17)#RandomForestRegressor(random_state=1)\n",
    "    reg3 = RandomForestRegressor(random_state=1,max_depth=112,n_estimators=1733)\n",
    "    reg4 = make_pipeline(StandardScaler(), SVR(C=1, epsilon=0.01))\n",
    "    ereg = VotingRegressor(estimators=[('gb', reg1), ('rf', reg2),('rf2',reg3),])#('svr',reg4)])\n",
    "    ereg = ereg.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    # Predict\n",
    "    y_pred = ereg.predict(X_train)\n",
    "    print(\"Training Error:\")\n",
    "    score(y_train,y_pred)\n",
    "    y_pred = ereg.predict(X_test)\n",
    "    print(\"Testing Error:\")\n",
    "    score(y_test,y_pred)\n",
    "\n",
    "    n_neighbors=17\n",
    "    print(\"5) KNN\")\n",
    "    knn = neighbors.KNeighborsRegressor(n_neighbors)\n",
    "    knn = knn.fit(X_train, y_train)\n",
    "    # Predict\n",
    "    y_pred = knn.predict(X_train)\n",
    "    print(\"Training Error:\",sep = '')\n",
    "    score(y_train,y_pred)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    print(\"Testing Error:\")\n",
    "    score(y_test,y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "7b8f50a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) Linear Regression \n",
      "Training Error:\n",
      "mae: 4.6939\n",
      "Testing Error:\n",
      "mae: 4.6251\n",
      "3) DT\n",
      "Training Error:\n",
      "mae: 0.0174\n",
      "Testing Error:\n",
      "mae: 2.2391\n",
      "4) Ensemble model\n",
      "Training Error:\n",
      "mae: 1.6333\n",
      "Testing Error:\n",
      "mae: 2.1013\n",
      "5) KNN\n",
      "Training Error:\n",
      "mae: 2.1707\n",
      "Testing Error:\n",
      "mae: 2.2882\n"
     ]
    }
   ],
   "source": [
    "model_output(x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "5b0df38c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance\n",
      "mae: 18.9569\n",
      "Model Performance\n",
      "mae: 2.0959\n",
      "Model Performance\n",
      "mae: 1.6\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    print('Model Performance')\n",
    "    mapp = score(test_labels,predictions)#np.mean(errors)\n",
    "    return mapp\n",
    "# Training classifiers\n",
    "reg1 = GradientBoostingRegressor(random_state=1)\n",
    "reg2 = neighbors.KNeighborsRegressor(11)#RandomForestRegressor(random_state=1)\n",
    "reg3 = RandomForestRegressor(random_state=1,max_depth=112,n_estimators=1733)\n",
    "# reg4 = make_pipeline(StandardScaler(), SVR(C=1, epsilon=0.01))\n",
    "ereg = VotingRegressor(estimators=[ ('gb', reg1),('rf', reg2),('rf2',reg3),])#('svr',reg4)]) \n",
    "ereg = ereg.fit(x_train,y_train)\n",
    "t=evaluate(ereg,given.values,gt.values)\n",
    "t=evaluate(ereg,x_test,y_test)\n",
    "t=evaluate(ereg,x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "02bb5f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "with open('ensemble','wb') as file:\n",
    "    pickle.dump(ereg,file)\n",
    "with open('ensemble','rb') as file:\n",
    "    model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "380fe78f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error:\n",
      "mae: 0.0174\n",
      "Testing Error:\n",
      "mae: 2.2685\n",
      "Real Testing Error:\n",
      "mae: 18.7884\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18.788409405255877"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = tree.DecisionTreeRegressor()\n",
    "clf = clf.fit(x_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = clf.predict(x_train)\n",
    "print(\"Training Error:\")\n",
    "score(y_train,y_pred)\n",
    "y_pred = clf.predict(x_test)\n",
    "print(\"Testing Error:\")\n",
    "score(y_test,y_pred)\n",
    "y_pred = clf.predict(given.values)\n",
    "print(\"Real Testing Error:\")\n",
    "score(gt.values,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "651ece59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error:\n",
      "mae: 0.7352\n",
      "Testing Error:\n",
      "mae: 1.9409\n",
      "Real Testing Error:\n",
      "mae: 18.9815\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18.98146656035835"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model = RandomForestRegressor(random_state=1,max_depth=112,n_estimators=1733)\n",
    "rf_model = rf_model.fit(x_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = rf_model.predict(x_train)\n",
    "print(\"Training Error:\")\n",
    "score(y_train,y_pred)\n",
    "y_pred = rf_model.predict(x_test)\n",
    "print(\"Testing Error:\")\n",
    "score(y_test,y_pred)\n",
    "y_pred = rf_model.predict(given.values)\n",
    "print(\"Real Testing Error:\")\n",
    "score(gt.values,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "e8acb60b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:31:31] WARNING: ../src/objective/regression_obj.cu:188: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Training Error:\n",
      "mae: 0.0178\n",
      "Testing Error:\n",
      "mae: 2.0503\n",
      "Real Testing Error:\n",
      "mae: 18.8795\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18.87949205631207"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xg\n",
    "xgb_r = xg.XGBRegressor(objective ='reg:linear',n_estimators=1788,max_depth=112, seed = 123)\n",
    "\n",
    "# Fitting the model\n",
    "xgb_r.fit(x_train, y_train)\n",
    " \n",
    "# Predict\n",
    "y_pred = xgb_r.predict(x_train)\n",
    "print(\"Training Error:\")\n",
    "score(y_train,y_pred)\n",
    "y_pred = xgb_r.predict(x_test)\n",
    "print(\"Testing Error:\")\n",
    "score(y_test,y_pred)\n",
    "y_pred = xgb_r.predict(given.values)\n",
    "print(\"Real Testing Error:\")\n",
    "score(gt.values,y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "fa5eb1ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-1.5.2-py3-none-manylinux2014_x86_64.whl (173.6 MB)\n",
      "     |████████████████████████████████| 173.6 MB 6.0 kB/s            \n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/rohanshah/adrl/lib/lib/python3.6/site-packages (from xgboost) (1.19.5)\n",
      "Requirement already satisfied: scipy in /home/rohanshah/adrl/lib/lib/python3.6/site-packages (from xgboost) (1.5.4)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.5.2\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6166dd93",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "fd6c527a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5) KNN\n",
      "{'n_neighbors': 11}\n",
      "Training Error:\n",
      "mae: 2.0799\n",
      "Testing Error:\n",
      "mae: 2.2753\n",
      "Real Testing Error: (1205, 605)\n",
      "mae: 18.4561\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18.456113416320882"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters={'n_neighbors':[11]}\n",
    "print(\"5) KNN\")\n",
    "knn = GridSearchCV(estimator=neighbors.KNeighborsRegressor(),param_grid=parameters)\n",
    "knn = knn.fit(x_train,y_train)\n",
    "print(knn.best_params_)\n",
    "knn = knn.best_estimator_ # 11 is best param\n",
    "# Predict\n",
    "y_pred = knn.predict(x_train)\n",
    "print(\"Training Error:\",sep = '')\n",
    "score(y_train,y_pred)\n",
    "y_pred = knn.predict(x_test)\n",
    "print(\"Testing Error:\")\n",
    "score(y_test,y_pred)\n",
    "print(\"Real Testing Error:\",given.values.shape)\n",
    "y_pred = knn.predict(given.values)\n",
    "score(y_pred,gt.values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
